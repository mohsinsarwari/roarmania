<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
		<meta name="description" content="" />
		<meta name="author" content="" />
		<title>ROARmania</title>
		<link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
		<!-- Core theme CSS (includes Bootstrap)-->
		<link href="css/styles.css" rel="stylesheet" />
	</head>
	<body id="page-top">
		<!-- Navigation-->
		<nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
			<div class="container px-4">
				<a class="navbar-brand" href="#page-top">ROARmania</a>
				<button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
				<div class="collapse navbar-collapse" id="navbarResponsive">
					<ul class="navbar-nav">
						<li class="nav-item"><a class="nav-link" href="#introduction">Introduction</a></li>
						<li class="nav-item"><a class="nav-link" href="#overview">Overview</a></li>
						<li class="nav-item"><a class="nav-link" href="#design">Design</a></li>
						<li class="nav-item"><a class="nav-link" href="#implementation">Implementation</a></li>
						<li class="nav-item"><a class="nav-link" href="#results">Results</a></li>
						<li class="nav-item"><a class="nav-link" href="#conclusion">Conclusion</a></li>
						<li class="nav-item"><a class="nav-link" href="#team">The Team</a></li>
					</ul>
				</div>
			</div>
		</nav>

		<!-- Header-->
		<header class="text-white">
			<div class="container px-4 text-center" style="padding-top: 75vh;">
				<h1 class="fw-bolder" style="font-size: 100px">ROARmania</h1>
				<p class="lead">Group 29: Frank Chiu, Nima Rezaeian, Shang Ma, ZhaoDong Wei, and Mohsin Sarwari</p>
			</div>
		</header>

		<!-- Introduction section-->
		<section id="introduction" style="padding: 2rem;">
			<div class="container px-2">
				<div class="row gx-2 justify-content-left">
					<div>
						<h2>Introduction</h2>
						<p>This website covers, in detail, the ins and outs of our final project for EECS 106A: Introduction to Robotics during the Fall 2021 semester. Please enjoy :) </p>
					</div>
				</div>
			</div>
		</section>

		<!-- Overview section-->
		<section class="bg-light" id="overview">
			<div class="container px-2">
				<div class="row gx-2 justify-content-left">
					<div>
						<h2>Project Overview</h2>
						<p style="text-indent: 30px; margin-bottom: 0px">
							Our final project, titled ROARMania, makes car racing video games with interactive elements come to life using existing robotics hardware and software platforms available at the FHL ViveCenter for Enhanced Reality at UC Berkeley. 
						</p>
						<p style="text-indent: 30px;">
							“ROAR” stands for Robot Open Autonomous Racing, an annual AI autonomous driving competition organized by the FHL ViveCenter. For each ROAR competition, student teams design perception, planning, and control algorithms to guide 1/10 RC race cars along a pre-specified track on the UC Berkeley campus. Meanwhile, “Mania” refers to car racing video games such as Trackmania and Mario Kart, in which race cars traverse tracks with interactive elements, such as Puzzle Panels, Dash Panels, and Power-Up Panels. When driven over in the video games’ simulated environments, these panels cause the race car’s behavior to change in specific ways.
						</p>
						<p>
							Our project fuses the design of perception, planning, and control algorithms that would enable the 1/10 RC ROAR cars, fondly dubbed <b>Simba</b> <i>(because it ROARs hehe)</i>, to:
						</p>
						<ol style="padding-left:2rem;">
							<li>Recognize patches of colored tape, placed next to the race track, as patches of interest, similar to the interactive elements of Trackmania, Mario Kart, or other car racing games </li>
							<li>Generate dynamically feasible trajectories for the RC race car to either approach or stay away from the recognized patches, as appropriate, while following the original ROAR race track (lane) </li>
							<li>Execute control signals for the ROAR car to follow the generated trajectories with minimal error</li>
						</ol>

						<p>
							With regards to the practical utility of the results of our project, the expected capabilities are two-fold: 
						</p>
						<ol style="padding-left:2rem;">
							<li>
								F1 formula races attract millions of viewers worldwide each year, while car racing video games have captivated the attention of generations of aspiring computer science enthusiasts. This project proved an interesting fusion of the thrilling nature of car racing with the excitement of playing car racing video games with interactive elements
							</li>
							<li>
								Our project results can also be used to enhance perception and planning for autonomous driving. In real-life scenarios, self-driving cars must often navigate complex traffic scenarios that demand a particular course of action, due to either traffic laws or human driving conventions. This is analogous to how the interactive elements we investigate in our project directly affect the dynamics of the vehicle. For example, in accordance with traffic laws, drivers in real life need to speed up or slow down when entering freeway ramps, depending on whether the ramp in question facilitates the movement of traffic entering or exiting the freeway. Thus, in the context of our project, these ramps may be interpreted as “boost” or “slow” patches in our task formulation. Meanwhile, patches of real-life roads with ice or mud are to be avoided to prevent loss of vehicle control, much as the “icy” or “muddy” patches in our project are to be avoided, since they would lead to undesirable changes in the race car dynamics.
							</li>
						</ol>
					</div>
				</div>
			</div>
		</section>

		<!-- Design section-->
		<section id="design">
			<div class="container px-2">
				<div class="row gx-2 justify-content-left">
					<h2>Design</h2>
					<p class="lead">There are 2 main sections of our design: the hardware design and the software design. Because we were working on the ROAR platform, the hardware side of the setup was, for the most part, done. The system works as follows: We start with our RC Car. The car has, connected to its receiver, an Arduino that can communicate directly with the car (send turn and throttle signals). We then attach an iPhone onto the car, which is running an app. Through BLE (Bluetooth Low Energy) the app communicates with the Arduino to send and receive ar signals. Finally, the app is connected to the computer by UDP websocket. This way the computer can receive camera data and vehicle information from the phone, and send back controls that go through the phone, through the Arduino, to the car to control it. The diagram looks as follows: </p>
					<div class="text-center">
						<img src="assets/hardwaredesign.png" width="1000px">
					</div>						
					<p class="lead">On the software side of things (the bulk of our work), our first task in creating the design for this problem was to modularize it. We decided to break the project down into 3 big modules: <b>Vision</b>, <b>Planning</b>, and <b>Control</b>. This would enable us to have barriers of abstraction such that we could tinker with different techniques at each level without causing errors in the others. The final design pipeline looks as follows:</p>
					<div class="text-center">
						<img src="assets/design.png" width="1000px">
					</div>	
				</div>
				<div class="subsection">
					<h4>Vision</h4>
					<p>The Vision Module is the first in line of the 3. It takes in as input the raw sensor data from the camera and vehicle. For our purposes, we were most interested in the RGB camera data of the rear facing camera. The vision module has 3 goals: </p>
					<ol>
						<li>Identify where the lane is (in pixel coordinates on the [1280 x 720] image)</li>
						<li>Identify where the patches are (if any) (in pixel coordinates on the [1280 x 720] image)</li>
						<li>Identify if we are currently on a patch (and if so, which type) (as a string that is None if we are not on a patch)</li>
					</ol>
					<p>
						Once these components have been identified, the vision module passes on the first to pieces of information to the planning module for the planning module to decide the next control. The third piece of information is sent directly to the control module, so that the control module can impose bounds on the controls to make the car behave as if though it is going over the patch it is on. 
					</p>				
				</div>
				<div class="subsection">
					<h4>Planning</h4>
					<p>As input the Planning module takes lane and patch information from the car. Based on this information and our desired behavior, the planning module comes up with a control for the current timestep that would move the car in the direction we desired.</p>						
				</div>
				<div class="subsection">
					<h4>Control</h4>
					<p>Finally, the control module. This module takes in two inputs: the control command from the planning module and the "on-patch" information from the perception module. The control module then tells the car to do what the planning module told it to do, but under whatever constraints the "on-patch" information gives it. For example, if the car is going over an ice patch, the control module will not be able to send a throttle signal greater than the set amount for an ice patch for a short duration of time. This means even if the planning module dictates a faster throttle, it will be cutoff to the ice patch bound in the control module before getting sent to the car. This is an important point, because it highlights the independence of the part of our project that pursues/avoids patchs and the part of our project that changes the behavior based on patch coverage.</p>						
				</div>
			</div>
		</section>

		<!-- Implementation section-->
		<section class="bg-light" id="implementation">
			<div class="container px-2">
				<div class="row gx-2 justify-content-left">
						<h2>Implementation</h2>
						<p class="lead">The code for the implementation can be found <a href="https://github.com/mohsinsarwari/ROAR">here</a>. The key files were worked on were:</p>
						<ul>
							<li><code>ROAR/agent_module/roarmania_agent.py</code></li>
							<li><code>ROAR/perception_module/roarmania_scene_detector.py</code></li>
							<li><code>ROAR/planning_module/roarmania_planner.py</code></li>
							<li><code>ROAR/control_module/real_world_image_based_pid_controller.py</code></li>
						</ul>
						<p>The agent file put together the pieces of the different modules</p>
				</div>
				<div class="subsection">
					<h4>Vision</h4>
					<p>All the code for the vision module is in roarmania_scene_detector.py. The main tool used for the implementation of the vision module was OpenCV. We first converted our input image from BGR (Blue Green Red) to HSV (Hue Saturation Value) format because it is easier to set masking bounds in the latter. We then down sample our image from [1280 x 720] to [256, 144] for faster processing. For each of the 3 tasks of the vision module, we need to look in different parts of the image. For the patches, we need to scan a large area of the ground so we can change our controls in time to pursue/avoid the patch. For the lane we need only to look right in front of the car because we are only interested in what to do in the next timestep. Finally, to see if we are on a patch, we look at a small strip of the image at the front of the car. Given these three sections, we apply masks of the appropriate colors (i.e. red and yellow for the lane, blue and white for the patches) to identify where the desired objects are (this took quite a bit of tuning). Then, for the lane, we take the median indicies of the highlighted points in the mask as our next lane point. For the patches, we run a blob detector on the mask to find their centers (that way we can detect more than one patch at once). Finally, to see if we are on a patch, we look to see what percentage of the image is highlighted. If there is more than a certain threshold percent of the patch color in that strip, we conclude that we are going over that patch. With this information, we create a dictionary and send it to the planning module. All together the Vision Pipeline Looks like this:</p>
					<div class="text-center">
						<img src="assets/vision.png" width="1000px">
					</div>							
				</div>
				<div class="subsection">
					<h4>Planning</h4>
					<p>All the code for the vision module is in roarmania_planner.py. For the planning module, we decided a greedy approach was best. Because our setup was such that we could only send controls to the car for the current timestep, it made sense to plan for the best in the current timestep. Most of our code was in the structure of if-else blocks. </p>						
				</div>
				<div class="subsection">
					<h4>Control</h4>
					<p>All the code for the vision module is in real_world_image_based_pid_controller.py.</p>						
				</div>
			</div>
		</section>

		<!-- Results section-->
		<section id="results">
			<div class="container px-2">
				<div class="row gx-2 justify-content-left">
					<h2>Results</h2>
					<p class="lead">And here we are! Click the video below to see our final results.</p>
				</div>
				<div class="text-center">
					<iframe src="https://drive.google.com/file/d/1CdVEAqVycVq3DjAhlbfV7LpTQHPwqhup/preview" width="640" height="480" allow="autoplay"></iframe>
				</div>
			</div>
		</section>

		<!-- Conclusions section-->
		<section class="bg-light" id="conclusion">
			<div class="container px-2">
				<div class="row gx-2 justify-content-left">
					<h2>Conclusions</h2>
					<p class="lead">One neat thing about this project is how much further it can be taken. There are ways to expand in every direction:</p>
					<div class="subsection">
						<h4>Future Work</h4>
						<p></p>
						<ul>
							<li><b style="font-size: 20px">Problem Setup</b></li>
							<ul>
								<li>Add more types of patches</li>
								<li>Introduce multi-agent racing with patches that affect other cars</li>
							</ul>
							<li><b style="font-size: 20px">Vision</b></li>
							<ul>
								<li>Make detection more robust (less errors)</li>
								<li>Add obstacle detection</li>
							</ul>
							<li><b style="font-size: 20px">Planning</b></li>
							<ul>
								<li>Plan for further ahead (not just current time-step)</li>
								<li>Add more sophisticated thinking for interesting senarios (e.g. avoid booster patch if near a turn as it will throw you off course)</li>
							</ul>
							<li><b style="font-size: 20px">Control</b></li>
							<ul>
								<li>Tune PD controller better to avoid oscillations in the car</li>
								<li>Increase base speed of car</li>
							</ul>
						</ul>
						
					</div>
				</div>
			</div>
		</section>

		<!-- Team section-->
		<section id="team" style="padding-top: 20px">
			<div class="container">
				<div class="row justify-content-center">
					<h2 style="text-align:center; margin-bottom: 20px">The Team</h2>
					<div class="row">
						<div style="text-align:center;" class="col">
							<img src='assets/mohsinsarwari.jpg' class="rounded-circle" width="200" height="200">
							<p class="lead">Mohsin Sarwari</p>
							<p class="text-justify" style="font-size: 14px;">
								Hi! As of Fa21, I'm a 4th year CS and Stats undergrad interested in all things Robotics. My research areas of focus lie in the overlap of Control Theory and Reinforcement Learning. For this project, I focused mainly on the Vision Module. 
							</p>
						</div>
						<div style="text-align:center;" class="col">
							<img src='assets/chiyuanchiu.jpg' class="rounded-circle" width="200" height="200">
							<p class="lead">Chih-Yuan Chiu</p>
							<p class="text-justify" style="font-size: 14px;">
								Hi! I'm a fourth-year EECS Ph.D. student, with background in control systems, optimization algorithms for SLAM and path planning. My main contributions were in the overall formulation of the planning tasks, acquisition of hardware and software platforms, and code in the control module.
							</p>
						</div>
						<div style="text-align:center;" class="col">
							<img src='assets/zhaodongwei.jpg' class="rounded-circle" width="200" height="200">
							<p class="lead">ZhaoDong Wei</p>
							<p class="text-justify" style="font-size: 14px;">
								Hi! As of Fa21, I'm a 4th year CS and Stats undergrad interested in all things Robotics. My research areas of focus lie in the overlap of Control Theory and Reinforcement Learning. For this project, I focused mainly on the Vision Module. 
							</p>
						</div>
						<div style="text-align:center;" class="col">
							<img src='assets/nimarezaeian.jpg' class="rounded-circle" width="200" height="200">
							<p class="lead">Nima Rezaeian</p>
							<p class="text-justify" style="font-size: 14px;">
								Hi! As of Fa21, I'm a 4th year CS and Stats undergrad interested in all things Robotics. My research areas of focus lie in the overlap of Control Theory and Reinforcement Learning. For this project, I focused mainly on the Vision Module. 
							</p>
						</div>
						<div style="text-align:center;" class="col">
							<img src='assets/shangma.jpg' class="rounded-circle" width="200" height="200">
							<p class="lead">Shang Ma</p>
							<p class="text-justify" style="font-size: 14px;">
								Hi! As of Fa21, I'm a 4th year CS and Stats undergrad interested in all things Robotics. My research areas of focus lie in the overlap of Control Theory and Reinforcement Learning. For this project, I focused mainly on the Vision Module. 
							</p>
						</div>
					</div>
				</div>
			</div>
		</section>

		<!-- Footer-->
		<footer class="py-5 bg-dark">
			<div class="container px-4"><p class="m-0 text-center text-white">Copyright &copy; ROARmania 2021</p></div>
		</footer>
		<!-- Bootstrap core JS-->
		<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
		<!-- Core theme JS-->
		<script src="js/scripts.js"></script>
	</body>
</html>
